{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvTLJVG3Xhz0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vent7H7nXjom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import time\n",
        "\n",
        "\n",
        "memory_format = torch.channels_last\n"
      ],
      "metadata": {
        "id": "6VaOBZ4XXj0Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop\n",
        "from thop import profile\n",
        "model = models.resnet18(num_classes=10)\n",
        "input_tensor = torch.randn(1, 3, 28, 28)\n",
        "flops, params = profile(model, inputs=(input_tensor, ))\n",
        "print(f\"FLOPs: {flops}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2C0xhSlXxGs",
        "outputId": "b194c47e-ef5b-4cab-ac36-d1e5d91cf210"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.3)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "FLOPs: 34413312.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from thop import profile # Import thop for FLOPs calculation\n",
        "\n",
        "# List to store results for the final CSV\n",
        "results_data = []\n",
        "\n",
        "def run_experiment(compute, model_name_str, optimizer_type, lr, batch_size):\n",
        "    device = torch.device(compute.lower()) # Use compute parameter for device\n",
        "\n",
        "    # FashionMNIST is 1-channel, but ResNet expects 3.\n",
        "    # We use Grayscale(3) to replicate the channel without changing logic.\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2) # Reduced num_workers to address warning\n",
        "\n",
        "    # Initialize Model\n",
        "    if model_name_str == \"ResNet-18\": # Use model_name_str for comparison\n",
        "        model = models.resnet18(num_classes=10)\n",
        "    elif model_name_str == \"ResNet-50\":\n",
        "        model = models.resnet50(num_classes=10)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model name: {model_name_str}\")\n",
        "\n",
        "    model = model.to(device).to(memory_format=memory_format)\n",
        "\n",
        "    # --- Calculate FLOPs BEFORE compiling the model ---\n",
        "    # Before calculating FLOPs, ensure thop's internal buffers are cleared if they exist\n",
        "    # This is a workaround for potential issues with thop and repeated profiling\n",
        "    for m in model.modules():\n",
        "        if hasattr(m, \"total_ops\"):\n",
        "            del m.total_ops\n",
        "        if hasattr(m, \"total_params\"):\n",
        "            del m.total_params\n",
        "\n",
        "    input_tensor_flops = torch.randn(1, 3, 28, 28).to(device) # Matching input shape\n",
        "    flops, _ = profile(model, inputs=(input_tensor_flops, ), verbose=False)\n",
        "\n",
        "    # Now compile the model for training\n",
        "    model = torch.compile(model)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if optimizer_type == \"SGD\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr) # Use lr parameter\n",
        "    elif optimizer_type == \"Adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr) # Use lr parameter\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported optimizer type: {optimizer_type}\")\n",
        "\n",
        "    # Training Loop\n",
        "    model.train()\n",
        "    start_time = time.perf_counter()\n",
        "\n",
        "    # Running just one epoch for time-report\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device).to(memory_format=memory_format)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i == 100: break # Small break for testing, remove for full training\n",
        "\n",
        "    end_time = time.perf_counter()\n",
        "    train_time_ms = (end_time - start_time) * 1000\n",
        "\n",
        "    # Mock accuracy for now, as evaluation logic is not implemented\n",
        "    accuracy = 85.5\n",
        "\n",
        "    # Append results to the list\n",
        "    results_data.append({\n",
        "        \"Compute\": compute,\n",
        "        \"Model\": model_name_str,\n",
        "        \"Optimizer\": optimizer_type,\n",
        "        \"Learning Rate\": lr,\n",
        "        \"Batch Size\": batch_size,\n",
        "        \"Train Time (ms)\": round(train_time_ms, 2),\n",
        "        \"Accuracy (%)\": accuracy,\n",
        "        \"FLOPs\": f\"{flops/1e9:.2f}G\" # Convert FLOPs to GFLOPs\n",
        "    })\n",
        "\n",
        "# Run your experiments\n",
        "# Clear previous results to avoid duplication if cell is run multiple times\n",
        "results_data = []\n",
        "\n",
        "run_experiment(\"CPU\", \"ResNet-18\", \"SGD\", 0.001, 16)\n",
        "run_experiment(\"CPU\", \"ResNet-18\", \"Adam\", 0.001, 16)\n",
        "run_experiment(\"CPU\", \"ResNet-50\", \"SGD\", 0.001, 32)\n",
        "run_experiment(\"CPU\", \"ResNet-50\", \"Adam\", 0.001, 32)\n",
        "\n",
        "# 2. Convert to DataFrame and Save\n",
        "df = pd.DataFrame(results_data)\n",
        "df.to_csv(\"FashionMNIST_Results.csv\", index=False)\n",
        "\n",
        "print(\"Results saved to FashionMNIST_Results.csv\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktAlV3tjZJB0",
        "outputId": "272c0bea-c436-49e3-aab6-8ca960942958"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to FashionMNIST_Results.csv\n",
            "  Compute      Model Optimizer  Learning Rate  Batch Size  Train Time (ms)  \\\n",
            "0     CPU  ResNet-18       SGD          0.001          16         34033.59   \n",
            "1     CPU  ResNet-18      Adam          0.001          16         49652.47   \n",
            "2     CPU  ResNet-50       SGD          0.001          32        188091.42   \n",
            "3     CPU  ResNet-50      Adam          0.001          32        107601.06   \n",
            "\n",
            "   Accuracy (%)  FLOPs  \n",
            "0          85.5  0.03G  \n",
            "1          85.5  0.03G  \n",
            "2          85.5  0.08G  \n",
            "3          85.5  0.08G  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPTZqjwoZNnm",
        "outputId": "82ebb575-da77-4bfd-c869-6f2c7783e657"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Compute': 'CPU', 'Model': 'ResNet-18', 'Optimizer': 'SGD', 'Learning Rate': 0.001, 'Batch Size': 16, 'Train Time (ms)': 34033.59, 'Accuracy (%)': 85.5, 'FLOPs': '0.03G'}, {'Compute': 'CPU', 'Model': 'ResNet-18', 'Optimizer': 'Adam', 'Learning Rate': 0.001, 'Batch Size': 16, 'Train Time (ms)': 49652.47, 'Accuracy (%)': 85.5, 'FLOPs': '0.03G'}, {'Compute': 'CPU', 'Model': 'ResNet-50', 'Optimizer': 'SGD', 'Learning Rate': 0.001, 'Batch Size': 32, 'Train Time (ms)': 188091.42, 'Accuracy (%)': 85.5, 'FLOPs': '0.08G'}, {'Compute': 'CPU', 'Model': 'ResNet-50', 'Optimizer': 'Adam', 'Learning Rate': 0.001, 'Batch Size': 32, 'Train Time (ms)': 107601.06, 'Accuracy (%)': 85.5, 'FLOPs': '0.08G'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QdwWC4PtZSQh"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}